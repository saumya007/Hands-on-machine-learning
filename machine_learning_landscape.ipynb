{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning landscape\n",
    "- Sampling Noise : \n",
    "    Non representative data by chance\n",
    "- Sampling bias : \n",
    "    Non representative data due to flawed sampling methods.\n",
    "- Don't put poor quality data. E.g if data is missing, either ignore that feature or fill it in with something like mean or median.\n",
    "- Enough relevant features should be present and not a lot of irrelevant features.\n",
    "- Coming up with good features is crucial. It is called feature engineering which involves :\n",
    "    -  Feature selection : Selecting good features.\n",
    "    -  Feature extraction : Combining several features into one (like dimensionality reduction)\n",
    "    -  Making new features by gathering new data.\n",
    "- If the data is noisy, complex models can detect patterns in noise as well and tend to overfit on training data.\n",
    "- Regularization allows model to generalize better.\n",
    "- Hyperparameter is a parameter of learning algorithm and not the model itself. \n",
    "- Reducing overfitting\n",
    "    - Selecting model with less parameters\n",
    "    - Gather more data\n",
    "    - Reduce noise in data\n",
    "- Reducing underfitting\n",
    "    - Selecting more powerful model with more parameters.\n",
    "    - Feeding better features to learning algorithm (Feature engineering)\n",
    "    - Reducing constraints on model (Reducing regularization)\n",
    "- 80,20 rule for training, testing\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
